{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XoNilKhg-58H"
   },
   "source": [
    "# <center>CS568 Deep Learning</center>\n",
    "<center>Department of Computer Science</center>\n",
    "<center>University of the Punjab</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "36ygGvYoQ7H4"
   },
   "source": [
    "## Assignment 3\n",
    "\n",
    "**Total Marks: 100**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju6LUGnEuBK7"
   },
   "source": [
    "In this assignment, you will implement momentum and Adam optimizers. Utilize the code base of Assignment A2 to integrate these optimizers. The problem is the same as Assignment A2 where you will train an MLP for multi-class classification on the MNIST dataset of handwritten digits. Please visit https://en.wikipedia.org/wiki/MNIST_database to familiarize yourself with the dataset. It contains 60,000 training images and 10,000 testing images. Each image is of size 28x28 pixels and contains a handwritten digit from 0 till 9. Use a code editor such as *Spyder* to complete this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oxDiR5X5uQnp"
   },
   "source": [
    "### What you will learn\n",
    "\n",
    "In this assignment, you will gain experience with the following parts for training and testing a neural network for multi-class classification:\n",
    "1. ADAM Optimization\n",
    "2. Comparison of ADAM and SGD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3HTwJEc0zvHf"
   },
   "source": [
    "### Files\n",
    "\n",
    "The main Python scripts in this assignment are the following.\n",
    "1. **driver_nn.py** creates the object of neural network class that can be further used to call train and test functions.\n",
    "2. **neural_network.py** contains train and test functions.\n",
    "3. **f_load_dataset.py** loads the MNIST dataset. Each 28x28 image is vectorized into a 784x1 vector so that it can be input to an MLP.\n",
    "4. **f_check_gradient.py** confirms the correctness of the analytical derivatives.\n",
    "5. **f_utils.py** consists of activation functions and their derivatives and loss functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "88cQiJ3n35B0"
   },
   "source": [
    "### Your job\n",
    "\n",
    "Look for the *'''ADD CODE HERE'''* comments in\n",
    "1. **f_utils.py**\n",
    "2. **f_check_gradient.py**\n",
    "3. **neural_network.py**\n",
    "\n",
    "Most of the missing code will be identical to your solution of Assignment A2. You can copy it from your solution.\n",
    "\n",
    "Once your code is completed,\n",
    "\n",
    "1. Run **driver.py** from the command line in 'train' mode using ADAM optimization.\n",
    "```\n",
    "python driver_nn.py --layer_dim 784 50 20 10 --activations None relu relu softmax --optimizer adam --epochs 1000 --loss mce --batch_size 64 --early_stopping --patience 10 --convergence_threshold 1e-5 --mode train --data_dir ../Data/ --check_grad\n",
    "```\n",
    "This will first check if all gradients are computed correctly. If so, it will train the model and save the training and validation losses in **loss_trainval_adam.png**.\n",
    "\n",
    "2. Once the model training has stopped, run **driver.py** from the command line in 'test' mode using the ADAM trained model.\n",
    "```\n",
    "python driver_nn.py --mode test --arch_file adam_model.json --weights_file adam_model.npy --data_dir ../Data/\n",
    "```\n",
    "This will generate the image\n",
    " - **ConfusionMatrixTest_adam.png**\n",
    "\n",
    "3. Run **driver.py** from the command line in 'train' mode using SGD optimization.\n",
    "```\n",
    "python driver_nn.py --layer_dim 784 50 20 10 --activations None relu relu softmax --optimizer sgd --epochs 1000 --loss mce --batch_size 64 --early_stopping --learning_rate 1e-3 --patience 10 --convergence_threshold 1e-5 --mode train --data_dir ../Data/ --check_grad\n",
    "```\n",
    "This will first check if all gradients are computed correctly. If so, it will train the model and save the training and validation losses in **loss_trainval_sgd.png**.\n",
    "\n",
    "4. Once the model training has stopped, run **driver.py** from the command line in 'test' mode using the SGD trained model.\n",
    "```\n",
    "python driver_nn.py --mode test --arch_file sgd_model.json --weights_file sgd_model.npy --data_dir ../Data/\n",
    "```\n",
    "This will generate the images\n",
    " - **ConfusionMatrixTest_sgd.png**\n",
    " - **adam_vs_sgd.png**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pCHl6-qkQ7H5"
   },
   "source": [
    "### Submission\n",
    "\n",
    "The submission .zip file should **ONLY** contain\n",
    "1. **f_utils.py**\n",
    "2. **f_check_gradient.py**\n",
    "3. **neural_network.py**\n",
    "4. **loss_trainval_adam.png**\n",
    "5. **loss_trainval_sgd.png**\n",
    "6. **ConfusionMatrixTest_adam.png**\n",
    "7. **ConfusionMatrixTest_sgd.png**\n",
    "8. **adam_vs_sgd.png**\n",
    "\n",
    "Once you are satisfied with your results, place the required files in CS568_Assignment3_YourRollNumber_YourName.zip and submit it in the Google Classroom.\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
